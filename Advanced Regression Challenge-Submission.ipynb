{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime = pd.read_csv(\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/master/New_York_offenses/NEW_YORK-Offenses_Known_to_Law_Enforcement_by_City_2013%20-%2013tbl8ny.csv\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaning, removing header rows\n",
    "crime.columns = crime.iloc[3]\n",
    "crime.droprow = crime.drop(crime.index[0:4], inplace=True)\n",
    "\n",
    "#rename columns\n",
    "crime.columns = ['city','population','violent_crime','murder','rape_revised',\n",
    "                 'rape_legacy','robbery','agg_assault','property_crime','burglary','larceny_theft',\n",
    "                 'motor_theft','arson3']\n",
    "#remove na from pop\n",
    "crime.dropna(subset = ['population'], inplace=True)\n",
    "#drop rape (revised def 1)\n",
    "crime.drop(['rape_revised','city'],axis=1,inplace=True)\n",
    "\n",
    "# Change the Arson null values to 0. \n",
    "crime['arson3'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove , and conver to float (for desired columns)\n",
    "crime = crime.replace(',','',regex=True)\n",
    "crime.iloc[:,:] = crime.iloc[:,:].apply(lambda x: pd.to_numeric(x))\n",
    "crime = crime.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348 entries, 0 to 347\n",
      "Data columns (total 11 columns):\n",
      "population        348 non-null int64\n",
      "violent_crime     348 non-null int64\n",
      "murder            348 non-null int64\n",
      "rape_legacy       348 non-null int64\n",
      "robbery           348 non-null int64\n",
      "agg_assault       348 non-null int64\n",
      "property_crime    348 non-null int64\n",
      "burglary          348 non-null int64\n",
      "larceny_theft     348 non-null int64\n",
      "motor_theft       348 non-null int64\n",
      "arson3            348 non-null int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 30.0 KB\n"
     ]
    }
   ],
   "source": [
    "crime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder</th>\n",
       "      <th>rape_legacy</th>\n",
       "      <th>robbery</th>\n",
       "      <th>agg_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larceny_theft</th>\n",
       "      <th>motor_theft</th>\n",
       "      <th>arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.480000e+02</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.003763e+04</td>\n",
       "      <td>201.594828</td>\n",
       "      <td>1.566092</td>\n",
       "      <td>5.864943</td>\n",
       "      <td>72.902299</td>\n",
       "      <td>121.261494</td>\n",
       "      <td>792.606322</td>\n",
       "      <td>119.683908</td>\n",
       "      <td>637.017241</td>\n",
       "      <td>35.905172</td>\n",
       "      <td>1.005747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.500374e+05</td>\n",
       "      <td>2815.268504</td>\n",
       "      <td>18.303673</td>\n",
       "      <td>60.425452</td>\n",
       "      <td>1031.032873</td>\n",
       "      <td>1706.131730</td>\n",
       "      <td>7659.724746</td>\n",
       "      <td>924.948789</td>\n",
       "      <td>6346.054451</td>\n",
       "      <td>403.423826</td>\n",
       "      <td>7.884612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.260000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.003000e+03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.233500e+03</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.842750e+04</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>287.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.396126e+06</td>\n",
       "      <td>52384.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1112.000000</td>\n",
       "      <td>19170.000000</td>\n",
       "      <td>31767.000000</td>\n",
       "      <td>141971.000000</td>\n",
       "      <td>16606.000000</td>\n",
       "      <td>117931.000000</td>\n",
       "      <td>7434.000000</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         population  violent_crime      murder  rape_legacy       robbery  \\\n",
       "count  3.480000e+02     348.000000  348.000000   348.000000    348.000000   \n",
       "mean   4.003763e+04     201.594828    1.566092     5.864943     72.902299   \n",
       "std    4.500374e+05    2815.268504   18.303673    60.425452   1031.032873   \n",
       "min    5.260000e+02       0.000000    0.000000     0.000000      0.000000   \n",
       "25%    3.003000e+03       2.000000    0.000000     0.000000      0.000000   \n",
       "50%    7.233500e+03       6.000000    0.000000     0.000000      1.000000   \n",
       "75%    1.842750e+04      22.000000    0.000000     2.000000      5.000000   \n",
       "max    8.396126e+06   52384.000000  335.000000  1112.000000  19170.000000   \n",
       "\n",
       "        agg_assault  property_crime      burglary  larceny_theft  motor_theft  \\\n",
       "count    348.000000      348.000000    348.000000     348.000000   348.000000   \n",
       "mean     121.261494      792.606322    119.683908     637.017241    35.905172   \n",
       "std     1706.131730     7659.724746    924.948789    6346.054451   403.423826   \n",
       "min        0.000000        0.000000      0.000000       0.000000     0.000000   \n",
       "25%        1.000000       40.500000      6.000000      31.000000     0.000000   \n",
       "50%        4.000000      112.500000     17.500000      94.000000     2.000000   \n",
       "75%       14.000000      341.000000     51.250000     287.250000     7.000000   \n",
       "max    31767.000000   141971.000000  16606.000000  117931.000000  7434.000000   \n",
       "\n",
       "           arson3  \n",
       "count  348.000000  \n",
       "mean     1.005747  \n",
       "std      7.884612  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      0.000000  \n",
       "max    132.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder</th>\n",
       "      <th>rape_legacy</th>\n",
       "      <th>robbery</th>\n",
       "      <th>agg_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larceny_theft</th>\n",
       "      <th>motor_theft</th>\n",
       "      <th>arson3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998854</td>\n",
       "      <td>0.986758</td>\n",
       "      <td>0.990839</td>\n",
       "      <td>0.998469</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.996265</td>\n",
       "      <td>0.970578</td>\n",
       "      <td>0.997946</td>\n",
       "      <td>0.992421</td>\n",
       "      <td>0.023680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violent_crime</th>\n",
       "      <td>0.998854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.994985</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.998059</td>\n",
       "      <td>0.978150</td>\n",
       "      <td>0.998762</td>\n",
       "      <td>0.996271</td>\n",
       "      <td>0.040651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder</th>\n",
       "      <td>0.986758</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997746</td>\n",
       "      <td>0.993104</td>\n",
       "      <td>0.990843</td>\n",
       "      <td>0.995403</td>\n",
       "      <td>0.993733</td>\n",
       "      <td>0.993175</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.128936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rape_legacy</th>\n",
       "      <td>0.990839</td>\n",
       "      <td>0.994985</td>\n",
       "      <td>0.997746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>0.994140</td>\n",
       "      <td>0.997843</td>\n",
       "      <td>0.992442</td>\n",
       "      <td>0.996260</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.093916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robbery</th>\n",
       "      <td>0.998469</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.993104</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>0.979525</td>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.996927</td>\n",
       "      <td>0.046528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agg_assault</th>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.990843</td>\n",
       "      <td>0.994140</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>0.976288</td>\n",
       "      <td>0.998561</td>\n",
       "      <td>0.995403</td>\n",
       "      <td>0.034251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_crime</th>\n",
       "      <td>0.996265</td>\n",
       "      <td>0.998059</td>\n",
       "      <td>0.995403</td>\n",
       "      <td>0.997843</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987137</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.076784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burglary</th>\n",
       "      <td>0.970578</td>\n",
       "      <td>0.978150</td>\n",
       "      <td>0.993733</td>\n",
       "      <td>0.992442</td>\n",
       "      <td>0.979525</td>\n",
       "      <td>0.976288</td>\n",
       "      <td>0.987137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982700</td>\n",
       "      <td>0.991464</td>\n",
       "      <td>0.174057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larceny_theft</th>\n",
       "      <td>0.997946</td>\n",
       "      <td>0.998762</td>\n",
       "      <td>0.993175</td>\n",
       "      <td>0.996260</td>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.998561</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.982700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996878</td>\n",
       "      <td>0.061608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motor_theft</th>\n",
       "      <td>0.992421</td>\n",
       "      <td>0.996271</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.996927</td>\n",
       "      <td>0.995403</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.991464</td>\n",
       "      <td>0.996878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arson3</th>\n",
       "      <td>0.023680</td>\n",
       "      <td>0.040651</td>\n",
       "      <td>0.128936</td>\n",
       "      <td>0.093916</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.034251</td>\n",
       "      <td>0.076784</td>\n",
       "      <td>0.174057</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>0.089692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                population  violent_crime    murder  rape_legacy   robbery  \\\n",
       "population        1.000000       0.998854  0.986758     0.990839  0.998469   \n",
       "violent_crime     0.998854       1.000000  0.992098     0.994985  0.999923   \n",
       "murder            0.986758       0.992098  1.000000     0.997746  0.993104   \n",
       "rape_legacy       0.990839       0.994985  0.997746     1.000000  0.995438   \n",
       "robbery           0.998469       0.999923  0.993104     0.995438  1.000000   \n",
       "agg_assault       0.999134       0.999942  0.990843     0.994140  0.999742   \n",
       "property_crime    0.996265       0.998059  0.995403     0.997843  0.998237   \n",
       "burglary          0.970578       0.978150  0.993733     0.992442  0.979525   \n",
       "larceny_theft     0.997946       0.998762  0.993175     0.996260  0.998735   \n",
       "motor_theft       0.992421       0.996271  0.997992     0.998764  0.996927   \n",
       "arson3            0.023680       0.040651  0.128936     0.093916  0.046528   \n",
       "\n",
       "                agg_assault  property_crime  burglary  larceny_theft  \\\n",
       "population         0.999134        0.996265  0.970578       0.997946   \n",
       "violent_crime      0.999942        0.998059  0.978150       0.998762   \n",
       "murder             0.990843        0.995403  0.993733       0.993175   \n",
       "rape_legacy        0.994140        0.997843  0.992442       0.996260   \n",
       "robbery            0.999742        0.998237  0.979525       0.998735   \n",
       "agg_assault        1.000000        0.997622  0.976288       0.998561   \n",
       "property_crime     0.997622        1.000000  0.987137       0.999666   \n",
       "burglary           0.976288        0.987137  1.000000       0.982700   \n",
       "larceny_theft      0.998561        0.999666  0.982700       1.000000   \n",
       "motor_theft        0.995403        0.998302  0.991464       0.996878   \n",
       "arson3             0.034251        0.076784  0.174057       0.061608   \n",
       "\n",
       "                motor_theft    arson3  \n",
       "population         0.992421  0.023680  \n",
       "violent_crime      0.996271  0.040651  \n",
       "murder             0.997992  0.128936  \n",
       "rape_legacy        0.998764  0.093916  \n",
       "robbery            0.996927  0.046528  \n",
       "agg_assault        0.995403  0.034251  \n",
       "property_crime     0.998302  0.076784  \n",
       "burglary           0.991464  0.174057  \n",
       "larceny_theft      0.996878  0.061608  \n",
       "motor_theft        1.000000  0.089692  \n",
       "arson3             0.089692  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "correlation_matrix = crime.corr()\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My features have very high correlations, except for arson which i will not use. \n",
    "There is also a very high correlation between pop and my vars, and property crime, so I am going to model using property crime per capita as my out come var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create faetures\n",
    "crime_feat = pd.DataFrame()\n",
    "crime_feat['violent_ind'] = crime.violent_crime.where(crime.violent_crime ==0,1)\n",
    "crime_feat['robbery_ind'] = crime.robbery.where(crime.robbery ==0,1)\n",
    "crime_feat['murder_ind'] = crime.murder.where(crime.murder ==0,1)\n",
    "crime_feat['rape_legacy'] = crime.rape_legacy.where(crime.rape_legacy ==0,1)\n",
    "crime_feat['assault_ind'] = crime.agg_assault.where(crime.agg_assault ==0,1)\n",
    "crime_feat['motor_ind'] = crime.motor_theft.where(crime.motor_theft ==0,1)\n",
    "crime_feat['pop_sq'] =crime['population'] **2\n",
    "crime_feat['sqrt_pop'] = np.sqrt(crime['population'])\n",
    "# crime_feat['burglary'] = crime.burglary.where(crime.burglary==0,1)\n",
    "# crime_feat['larceny_theft'] = crime.larceny_theft.where(crime.larceny_theft ==0,1)\n",
    "crime_feat['burglary'] = crime['burglary']\n",
    "crime_feat['larceny_theft'] = crime['larceny_theft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbohan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:160: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "#now scale!\n",
    "\n",
    "# Select only numeric variables to scale.\n",
    "df_num= crime_feat.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Save the column names.\n",
    "names=df_num.columns\n",
    "\n",
    "# Scale, then turn the resulting numpy array back into a data frame with the correct column names.\n",
    "feat_scaled = pd.DataFrame(preprocessing.scale(df_num), columns=names, index=crime.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make property crime ctegorical - using mean of 112.5 as cutoff\n",
    "feat_scaled['property_crime_per_cap'] = crime['property_crime']/crime['population']\n",
    "feat_scaled['prop_ind']= np.where(feat_scaled['property_crime_per_cap'] >= np.median(feat_scaled['property_crime_per_cap']),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Independent variables\n",
    "X = feat_scaled.drop(['property_crime_per_cap','prop_ind'], axis=1, inplace=False)\n",
    "# Dependent variable\n",
    "Y = feat_scaled['prop_ind']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Vanilla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pick value of C that gives best accuracy on test test\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import model_selection\n",
    "# my_C = []\n",
    "# my_accuracy = []\n",
    "# for C in np.arange(1,2000,.1):\n",
    "#     lr = LogisticRegression(C=C)\n",
    "#     X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "#     fit = lr.fit(X_train, Y_train)\n",
    "#     my_C.append(C)\n",
    "#     my_accuracy.append(fit.score(X_test,Y_test))\n",
    "\n",
    "\n",
    "# plt.plot(my_C, my_accuracy)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = pd.DataFrame({\"log_score\": my_accuracy,\"C\":my_C})\n",
    "# scores['log_score'].argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores.iloc[2698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [[ -1.11454833e-01   1.01500294e+00   2.58000391e-01   8.13176095e-01\n",
      "    1.09151078e+00   4.68546973e-01  -1.90230491e+02  -2.08031365e+01\n",
      "   -1.82767081e+01   2.28082789e+02]]\n",
      "\n",
      "Intercept: \n",
      " [ 2.91931738]\n",
      "\n",
      " Logistic Accuracy by property crime per capita\n",
      "prop_ind   0   1\n",
      "row_0           \n",
      "0         51   6\n",
      "1          7  41\n",
      "\n",
      "The accuracy for train set:  0.8683127572016461\n",
      "The accuracy for test set:  0.8761904761904762\n",
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.86111111  0.91666667  0.94444444  0.88888889  0.79411765  0.91176471\n",
      "  0.88235294  0.85294118  0.82352941  0.94117647]\n",
      "\n",
      "Overall Logistic Regression R2: 0.88 (+/- 0.09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare a logistic regression classifier.\n",
    "X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "lr = LogisticRegression(C=1e20)\n",
    "# Fit the variables to the logistic model.\n",
    "fit = lr.fit(X_train, Y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCoefficients: \\n', fit.coef_)\n",
    "print('\\nIntercept: \\n', fit.intercept_)\n",
    "\n",
    "logistic_pred_y = fit.predict(X_test)\n",
    "print('\\n Logistic Accuracy by property crime per capita')\n",
    "print(pd.crosstab(logistic_pred_y, Y_test))\n",
    "\n",
    "\n",
    "print('\\nThe accuracy for train set: ',format(fit.score(X_train, Y_train)))\n",
    "print('The accuracy for test set: ',format(fit.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "score = cross_val_score(fit, X, Y, cv=10)\n",
    "print('\\nEach Cross Validated R2 score: \\n', score)\n",
    "print(\"\\nOverall Logistic Regression R2: %0.2f (+/- %0.2f)\\n\" % (score.mean(), score.std() * 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxHAnIpIQw52ISEL/D8Wbp/dVr5FNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc84c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find correct lambda to use \n",
    "# X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "my_alpha = []\n",
    "my_accuracy = []\n",
    "for lambd in np.arange(0.01,2000,.1):\n",
    "    ridgeregr =LogisticRegression(penalty='l2',C=lambd)\n",
    "    X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "    fit = ridgeregr.fit(X_train, Y_train)\n",
    "    my_alpha.append(lambd)\n",
    "    my_accuracy.append(fit.score(X_test,Y_test))\n",
    "\n",
    "\n",
    "plt.plot(my_alpha, my_accuracy)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame({\"ridge_score\": my_accuracy,\"lambda\":my_alpha})\n",
    "scores['ridge_score'].argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lambda         270.810000\n",
       "ridge_score      0.904762\n",
       "Name: 2708, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.iloc[2708]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [[ -0.13120499   0.947479     0.15172859   0.60659779   0.86058378\n",
      "    0.36463447  -2.36485594 -10.44272455  15.47041288  58.92434864]]\n",
      "\n",
      "Intercept: \n",
      " [ 4.57711449]\n",
      "\n",
      " Ridge Accuracy by property crime per capita\n",
      "prop_ind   0   1\n",
      "row_0           \n",
      "0         51   3\n",
      "1          7  44\n",
      "\n",
      "The accuracy for train set:  0.8600823045267489\n",
      "The accuracy for test set:  0.9047619047619048\n",
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.80555556  0.91666667  0.83333333  0.88888889  0.82352941  0.91176471\n",
      "  0.82352941  0.85294118  0.82352941  0.91176471]\n",
      "\n",
      "Overall Ridge Regression R2: 0.86 (+/- 0.08)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare a logistic regression classifier.\n",
    "X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "ridgeregr = LogisticRegression(penalty='l2', C=270.8)\n",
    "# Fit the variables to the logistic model.\n",
    "ridge_fit = ridgeregr.fit(X_train, Y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCoefficients: \\n', ridge_fit.coef_)\n",
    "print('\\nIntercept: \\n', ridge_fit.intercept_)\n",
    "\n",
    "ridge_pred_y = ridge_fit.predict(X_test)\n",
    "print('\\n Ridge Accuracy by property crime per capita')\n",
    "print(pd.crosstab(ridge_pred_y, Y_test))\n",
    "\n",
    "\n",
    "print('\\nThe accuracy for train set: ',format(ridge_fit.score(X_train, Y_train)))\n",
    "print('The accuracy for test set: ',format(ridge_fit.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "score = cross_val_score(ridge_fit, X, Y, cv=10)\n",
    "print('\\nEach Cross Validated R2 score: \\n', score)\n",
    "print(\"\\nOverall Ridge Regression R2: %0.2f (+/- %0.2f)\\n\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies of the ridge regression is slightly less than than the vanilla, using the C value we found. \n",
    "The high C value used for the vanilla, performs very similarly to a lower C value for ridge (higher regularization). \n",
    "Does this mean that reg doesnt have much of an impact? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcdc90b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find correct lambda to use \n",
    "# X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "my_alpha = []\n",
    "my_accuracy = []\n",
    "for lambd in np.arange(0.01,1000,1):\n",
    "    lasso =LogisticRegression(penalty='l1',C=lambd)\n",
    "    X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "    lasso_fit = lasso.fit(X_train, Y_train)\n",
    "    my_alpha.append(lambd)\n",
    "    my_accuracy.append(lasso_fit.score(X_test,Y_test))\n",
    "\n",
    "\n",
    "plt.plot(my_alpha, my_accuracy)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame({\"lasso_score\": my_accuracy,\"lambda\":my_alpha})\n",
    "scores['lasso_score'].argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lambda         17.010000\n",
       "lasso_score     0.914286\n",
       "Name: 17, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [[ -0.09067834   0.83832173   0.17134663   0.54877907   0.79100542\n",
      "    0.3404959  -17.79775038  -8.97066467   8.88599551  55.51959787]]\n",
      "\n",
      "Intercept: \n",
      " [ 2.97640691]\n",
      "\n",
      " Lasso Accuracy by property crime per capita\n",
      "prop_ind   0   1\n",
      "row_0           \n",
      "0         50   3\n",
      "1          8  44\n",
      "\n",
      "The accuracy for train set:  0.8600823045267489\n",
      "The accuracy for test set:  0.8952380952380953\n",
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.80555556  0.91666667  0.83333333  0.88888889  0.79411765  0.88235294\n",
      "  0.85294118  0.85294118  0.82352941  0.82352941]\n",
      "\n",
      "Overall Lasso Regression R2: 0.85 (+/- 0.07)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Independent variables\n",
    "X_lass = feat_scaled.drop(['property_crime_per_cap','prop_ind'], axis=1, inplace=False)\n",
    "# Dependent variable\n",
    "Y_lass = feat_scaled['prop_ind']\n",
    "\n",
    "# Declare a logistic regression classifier.\n",
    "X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X_lass,Y_lass, test_size=0.30, random_state=42) \n",
    "lassoregr = LogisticRegression(penalty='l1', C=17.01)\n",
    "# Fit the variables to the logistic model.\n",
    "lasso_fit = lassoregr.fit(X_train, Y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('\\nCoefficients: \\n', lasso_fit.coef_)\n",
    "print('\\nIntercept: \\n', lasso_fit.intercept_)\n",
    "\n",
    "lasso_pred_y = lasso_fit.predict(X_test)\n",
    "print('\\n Lasso Accuracy by property crime per capita')\n",
    "print(pd.crosstab(lasso_pred_y, Y_test))\n",
    "\n",
    "\n",
    "print('\\nThe accuracy for train set: ',format(lasso_fit.score(X_train, Y_train)))\n",
    "print('The accuracy for test set: ',format(lasso_fit.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "score = cross_val_score(lasso_fit, X_lass, Y_lass, cv=10)\n",
    "print('\\nEach Cross Validated R2 score: \\n', score)\n",
    "print(\"\\nOverall Lasso Regression R2: %0.2f (+/- %0.2f)\\n\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso has a lower acuracy than ridge or log. It also doesnt seem that using the lambda value we found, mininmizes any of my coefificents to zero. It also seems that lasso produces more false postive results. \n",
    "\n",
    "@Vincent - can we discuss? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
