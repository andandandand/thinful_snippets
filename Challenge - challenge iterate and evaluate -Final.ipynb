{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "--Do any of your classifiers seem to overfit?\n",
    "\n",
    "--Which seem to perform the best? Why?\n",
    "\n",
    "--What features seemed to be most impactful to performance?\n",
    "\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Negative Words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_raw = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_raw.columns = ['Sentence', 'Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_raw.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative = ['waste', 'breaks', 'lousy','cannot','disappoint','disappointed','junk','poor',\n",
    "           \"doesn't\", 'bad', \"don't\", 'problem', 'misleading', 'difficult','unreliable','horrible','broken','fail', 'terrible']\n",
    "\n",
    "for word in negative:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(word)] = sms_raw.Sentence.str.contains(\n",
    "        ' ' + str(word) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_raw['Sentiment'] = (sms_raw['Sentiment'] == 0)\n",
    "# Note that if you run this cell a second time everything will become false.\n",
    "# So... Don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xadd0898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAF5CAYAAACLJMP1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbdf1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(sms_raw.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sms_raw[negative]  #features\n",
    "target = sms_raw['Sentiment']  #ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of mislabeled points out of a total 700 points : 318\n",
      "Test: Number of mislabeled points out of a total 300 points : 127\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "   data, target, test_size=0.30, random_state=42)\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# # Fit our model to the data.\n",
    "bnb.fit(data_train, target_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "test_pred = bnb.predict(data_test)  #making preductions using test features\n",
    "train_pred = bnb.predict(data_train)\n",
    "train_confusion = pd.crosstab(target_train, train_pred)\n",
    "test_confusion = pd.crosstab(target_test, test_pred)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Train: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_train.shape[0],\n",
    "    (target_train != train_pred).sum()\n",
    "))\n",
    "\n",
    "\n",
    "print(\"Test: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_test.shape[0],\n",
    "    (target_test != test_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.545714285714\n",
      "Specificity :  0.982658959538\n",
      "Sensitivity :  0.118644067797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy train \n",
    "accuracy=(train_confusion.iloc[0,0]+train_confusion.iloc[1,1])/len(target_train)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = train_confusion.iloc[0,0]/(train_confusion.iloc[0,1]+train_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = train_confusion.iloc[1,1]/(train_confusion.iloc[1,0]+train_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.576666666667\n",
      "Specificity :  0.993506493506\n",
      "Sensitivity :  0.13698630137\n"
     ]
    }
   ],
   "source": [
    "#Accuracy test\n",
    "accuracy=(test_confusion.iloc[0,0]+test_confusion.iloc[1,1])/len(target_test)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = test_confusion.iloc[0,0]/(test_confusion.iloc[0,1]+test_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = test_confusion.iloc[1,1]/(test_confusion.iloc[1,0]+test_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        340      6\n",
      "True         312     42\n",
      "\n",
      "\n",
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        153      1\n",
      "True         126     20\n"
     ]
    }
   ],
   "source": [
    "print(train_confusion)\n",
    "print('\\n')\n",
    "\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our train and test groups have similar accuracies, specificities and sensitivities, so there doesn't seem to be much overfitting. The sensitivies are low though, meaning the model is not great at correctly identifying positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 - Positive words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header = None)\n",
    "\n",
    "amazon.columns = ['Sentence', 'Sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive = ['good','great','excellent','nice','love','beautiful','best','enjoy',\n",
    "                  'highly','brilliant','tremendous','loved','awesome','impressed','perfect','pleased']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#turn sentiment into boolean\n",
    "amazon['Sentiment'] = (amazon['Sentiment'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in positive:\n",
    "    amazon[word] = amazon['Sentence'].apply(lambda x: word in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of mislabeled points out of a total 700 points : 240\n",
      "Test: Number of mislabeled points out of a total 300 points : 101\n"
     ]
    }
   ],
   "source": [
    "data = amazon[positive]\n",
    "target = amazon['Sentiment']\n",
    "\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "#these data_train, etc are different than what defined above. cocneptually play different role\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "   data, target, test_size=0.30, random_state=42)  #train_test_split makes a random choice\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# # Fit our model to the data.\n",
    "bnb.fit(data_train, target_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "test_pred = bnb.predict(data_test)\n",
    "train_pred = bnb.predict(data_train)\n",
    "train_confusion = pd.crosstab(target_train, train_pred)\n",
    "test_confusion = pd.crosstab(target_test, test_pred)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Train: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_train.shape[0],\n",
    "    (target_train != train_pred).sum()\n",
    "))\n",
    "\n",
    "\n",
    "print(\"Test: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_test.shape[0],\n",
    "    (target_test != test_pred).sum()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.657142857143\n",
      "Specificity :  0.95197740113\n",
      "Sensitivity :  0.35549132948\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy train \n",
    "accuracy=(train_confusion.iloc[0,0]+train_confusion.iloc[1,1])/len(target_train)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = train_confusion.iloc[0,0]/(train_confusion.iloc[0,1]+train_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = train_confusion.iloc[1,1]/(train_confusion.iloc[1,0]+train_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.663333333333\n",
      "Specificity :  0.924657534247\n",
      "Sensitivity :  0.415584415584\n"
     ]
    }
   ],
   "source": [
    "#Accuracy test\n",
    "accuracy=(test_confusion.iloc[0,0]+test_confusion.iloc[1,1])/len(target_test)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = test_confusion.iloc[0,0]/(test_confusion.iloc[0,1]+test_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = test_confusion.iloc[1,1]/(test_confusion.iloc[1,0]+test_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        337     17\n",
      "True         223    123\n",
      "\n",
      "\n",
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        135     11\n",
      "True          90     64\n"
     ]
    }
   ],
   "source": [
    "print(train_confusion)\n",
    "print('\\n')\n",
    "\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once again, our train and test groups have similar accuracies, specificities and sensitivities, so there doesn't seem to be much overfitting. We are more accurate than the first iteration, and while the specificity is lower (still good at predicting negative reviews), the sensitivies are higher, meaning we are getting better at predicting positive reviews, albeit still not great. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3 frequent positive words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at most common words in positive reviews\n",
    "\n",
    "amazon = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header = None)\n",
    "\n",
    "amazon.columns = ['Sentence', 'Sentiment']\n",
    "\n",
    "amazon['Sentiment'] = (amazon['Sentiment'] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outcome var\n",
    "good = amazon.loc[amazon.Sentiment==1,'Sentence']\n",
    "\n",
    "def modes(amz):\n",
    "    counting = {}\n",
    "    for item in amz.str.split('\\s+'):\n",
    "        for word in item:\n",
    "            if word in counting:\n",
    "                counting[word] += 1\n",
    "            else:\n",
    "                counting[word] = 1\n",
    "\n",
    "    \n",
    "    most = max(counting.values())\n",
    "\n",
    "    least = min(counting.values())\n",
    "    \n",
    "    result = []\n",
    "    #lets set the mode to words appearing more than 25 times\n",
    "    for key,value in counting.items():\n",
    "        if value >=25:\n",
    "            result.append(key)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode_good = modes(good)\n",
    "for word in mode_good:\n",
    "    amazon[str(word)] = amazon.Sentence.str.contains(\n",
    "        str(word),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of mislabeled points out of a total 700 points : 222\n",
      "Test: Number of mislabeled points out of a total 300 points : 112\n"
     ]
    }
   ],
   "source": [
    "data = amazon[mode_good]\n",
    "target = amazon['Sentiment']\n",
    "\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "#these data_train, etc are different than what defined above. cocneptually play different role\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "   data, target, test_size=0.30, random_state=42)  #train_test_split makes a random choice\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# # Fit our model to the data.\n",
    "bnb.fit(data_train, target_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "test_pred = bnb.predict(data_test)\n",
    "train_pred = bnb.predict(data_train)\n",
    "train_confusion = pd.crosstab(target_train, train_pred)\n",
    "test_confusion = pd.crosstab(target_test, test_pred)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Train: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_train.shape[0],\n",
    "    (target_train != train_pred).sum()\n",
    "))\n",
    "\n",
    "\n",
    "print(\"Test: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_test.shape[0],\n",
    "    (target_test != test_pred).sum()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.682857142857\n",
      "Specificity :  0.805084745763\n",
      "Sensitivity :  0.557803468208\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy train \n",
    "accuracy=(train_confusion.iloc[0,0]+train_confusion.iloc[1,1])/len(target_train)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = train_confusion.iloc[0,0]/(train_confusion.iloc[0,1]+train_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = train_confusion.iloc[1,1]/(train_confusion.iloc[1,0]+train_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.626666666667\n",
      "Specificity :  0.719178082192\n",
      "Sensitivity :  0.538961038961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy test\n",
    "accuracy=(test_confusion.iloc[0,0]+test_confusion.iloc[1,1])/len(target_test)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = test_confusion.iloc[0,0]/(test_confusion.iloc[0,1]+test_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = test_confusion.iloc[1,1]/(test_confusion.iloc[1,0]+test_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        285     69\n",
      "True         153    193\n",
      "\n",
      "\n",
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        105     41\n",
      "True          71     83\n"
     ]
    }
   ],
   "source": [
    "print(train_confusion)\n",
    "print('\\n')\n",
    "\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our accuracy, sensitivity and spec. are all a bit higher in the train group, so there might be a case of overfitting going on.  \n",
    "The specificity is lower than the previous iterations, so we are not as good at predicting negative reviews, but still pretty good at it. However, sensitivity is higher, so we are getting better at predicting positive reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4 -frequent negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at most common words in negative reviews\n",
    "\n",
    "amazon = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header = None)\n",
    "\n",
    "amazon.columns = ['Sentence', 'Sentiment']\n",
    "\n",
    "amazon['Sentiment'] = (amazon['Sentiment'] == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outcome var\n",
    "bad = amazon.loc[amazon.Sentiment==0,'Sentence']\n",
    "\n",
    "def modes(amz):\n",
    "    counting = {}\n",
    "    for item in amz.str.split('\\s+'):\n",
    "        for word in item:\n",
    "            if word in counting:\n",
    "                counting[word] += 1\n",
    "            else:\n",
    "                counting[word] = 1\n",
    "\n",
    "    \n",
    "    most = max(counting.values())\n",
    "\n",
    "    least = min(counting.values())\n",
    "    \n",
    "    result = []\n",
    "    #lets set the mode to words appearing more than 25 times\n",
    "    for key,value in counting.items():\n",
    "        if value >=25:\n",
    "            result.append(key)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode_bad = modes(bad)\n",
    "for word in mode_bad:\n",
    "    amazon[str(word)] = amazon.Sentence.str.contains(\n",
    "        str(word),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of mislabeled points out of a total 700 points : 222\n",
      "Test: Number of mislabeled points out of a total 300 points : 112\n"
     ]
    }
   ],
   "source": [
    "data = amazon[mode_bad]\n",
    "target = amazon['Sentiment']\n",
    "\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "#these data_train, etc are different than what defined above. cocneptually play different role\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "   data, target, test_size=0.30, random_state=42)  #train_test_split makes a random choice\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# # Fit our model to the data.\n",
    "bnb.fit(data_train, target_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "test_pred = bnb.predict(data_test)\n",
    "train_pred = bnb.predict(data_train)\n",
    "train_confusion = pd.crosstab(target_train, train_pred)\n",
    "test_confusion = pd.crosstab(target_test, test_pred)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Train: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_train.shape[0],\n",
    "    (target_train != train_pred).sum()\n",
    "))\n",
    "\n",
    "\n",
    "print(\"Test: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_test.shape[0],\n",
    "    (target_test != test_pred).sum()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.682857142857\n",
      "Specificity :  0.557803468208\n",
      "Sensitivity :  0.805084745763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy train \n",
    "accuracy=(train_confusion.iloc[0,0]+train_confusion.iloc[1,1])/len(target_train)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = train_confusion.iloc[0,0]/(train_confusion.iloc[0,1]+train_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = train_confusion.iloc[1,1]/(train_confusion.iloc[1,0]+train_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.626666666667\n",
      "Specificity :  0.538961038961\n",
      "Sensitivity :  0.719178082192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy test\n",
    "accuracy=(test_confusion.iloc[0,0]+test_confusion.iloc[1,1])/len(target_test)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = test_confusion.iloc[0,0]/(test_confusion.iloc[0,1]+test_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = test_confusion.iloc[1,1]/(test_confusion.iloc[1,0]+test_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        193    153\n",
      "True          69    285\n",
      "\n",
      "\n",
      "col_0      False  True \n",
      "Sentiment              \n",
      "False         83     71\n",
      "True          41    105\n"
     ]
    }
   ],
   "source": [
    "print(train_confusion)\n",
    "print('\\n')\n",
    "\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our accuracy and sensitivity are all a bit higher in the train group, so there might be a case of overfitting going on, once again. The accuracy is about the same as the frquent positive words classifier  but now the spec is a lot lower and sensitivity is much higher, meaning we are getting worse at predicting negative reviews, and better at predicting positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Most common words shared between pos and neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header = None)\n",
    "\n",
    "amazon.columns = ['Sentence', 'Sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#turn sentiment into boolean\n",
    "amazon['Sentiment'] = (amazon['Sentiment'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outcome var\n",
    "shared = amazon.loc[:,'Sentence']\n",
    "\n",
    "def modes(amz):\n",
    "    counting = {}\n",
    "    for item in amz.str.split('\\s+'):\n",
    "        for word in item:\n",
    "            if word in counting:\n",
    "                counting[word] += 1\n",
    "            else:\n",
    "                counting[word] = 1\n",
    "\n",
    "    \n",
    "    most = max(counting.values())\n",
    "\n",
    "    least = min(counting.values())\n",
    "    \n",
    "    result = []\n",
    "    #lets set the mode to words appearing more than 25 times\n",
    "    for key,value in counting.items():\n",
    "        if value >=25:\n",
    "            result.append(key)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode_shared = modes(shared)\n",
    "for word in mode_shared:\n",
    "    amazon[str(word)] = amazon.Sentence.str.contains(\n",
    "        str(word),\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of mislabeled points out of a total 700 points : 189\n",
      "Test: Number of mislabeled points out of a total 300 points : 94\n"
     ]
    }
   ],
   "source": [
    "data = amazon[mode_shared]\n",
    "target = amazon['Sentiment']\n",
    "\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "#these data_train, etc are different than what defined above. cocneptually play different role\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "   data, target, test_size=0.30, random_state=42)  #train_test_split makes a random choice\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# # Fit our model to the data.\n",
    "bnb.fit(data_train, target_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "test_pred = bnb.predict(data_test)\n",
    "train_pred = bnb.predict(data_train)\n",
    "train_confusion = pd.crosstab(target_train, train_pred)\n",
    "test_confusion = pd.crosstab(target_test, test_pred)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Train: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_train.shape[0],\n",
    "    (target_train != train_pred).sum()\n",
    "))\n",
    "\n",
    "\n",
    "print(\"Test: Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data_test.shape[0],\n",
    "    (target_test != test_pred).sum()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.73\n",
      "Specificity :  0.779661016949\n",
      "Sensitivity :  0.679190751445\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy train \n",
    "accuracy=(train_confusion.iloc[0,0]+train_confusion.iloc[1,1])/len(target_train)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = train_confusion.iloc[0,0]/(train_confusion.iloc[0,1]+train_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = train_confusion.iloc[1,1]/(train_confusion.iloc[1,0]+train_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.686666666667\n",
      "Specificity :  0.712328767123\n",
      "Sensitivity :  0.662337662338\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy test\n",
    "accuracy=(test_confusion.iloc[0,0]+test_confusion.iloc[1,1])/len(target_test)\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "#Specifity\n",
    "Specificity = test_confusion.iloc[0,0]/(test_confusion.iloc[0,1]+test_confusion.iloc[0,0])\n",
    "print('Specificity : ', Specificity )\n",
    "\n",
    "#Sensitivity\n",
    "Sensitivity = test_confusion.iloc[1,1]/(test_confusion.iloc[1,0]+test_confusion.iloc[1,1])\n",
    "print('Sensitivity : ', Sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69900000000000007"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores = model_selection.cross_val_score(bnb,data,target,cv=10) #combined accuract. \n",
    "#cross_val_score will give test scores for each of the different splits\n",
    "#prints accuracy\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        276     78\n",
      "True         111    235\n",
      "\n",
      "\n",
      "col_0      False  True \n",
      "Sentiment              \n",
      "False        104     42\n",
      "True          52    102\n"
     ]
    }
   ],
   "source": [
    "print(train_confusion)\n",
    "print('\\n')\n",
    "\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our accuracy and spec are all a bit higher in the train group, so there might be a case of minor overfitting going on, once again. However, the accuracy we found is the highest thus far. Also, while the spec or sensitivity is not the highest we've seen for either score, this iteration has the most balance between the two (i.e. combined, they are the highest)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
